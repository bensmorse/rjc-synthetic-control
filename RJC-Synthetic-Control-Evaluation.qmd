---
title: "Synthetic Control Evaluation of the RJC Pilot Project"
format: html
editor: source
---

## Background on RJC

```{r}
#| warning: false
#| include: false

# load packages
library(readxl)
library(tidyverse)
library(dplyr)
library(ggplot2)
library(tidyquant)
library(magrittr) 
library(dplyr)

library(Synth)
library(SCtools)
library(skimr)
library(zoo)
library(lubridate)
library(dplyr)
library(tidysynth)
library(janitor)
library(flextable)
library(RColorBrewer)
library(gt)
library(kableExtra)


```

In 2024, Multnomah County, Oregon, launched the [Reimaginging Justice in Cully (RJC)](https://multco.us/info/reimagining-justice-cully) pilot project. Funded by federal Bureau of Justice Assistance, RJC sought to reduce low-level crimes and improve community safety by adopting community-driven approaches to crime reduction such as trust-building between police and residents, place-based public safety interventions, and diversion progarms for at-risk youth.

Together with former colleagues from Social Impact, I conducted a synthetic control analysis of the impact of RJC on the four types of low-level crime targeted by the program -- assault, motor vehicle theft, larceny, and vandalism. The analysis draws entirely on publicly available census data and neighborhood-level crime data accessible through [Portland's Crime Statistics Dashboard](https://public.tableau.com/app/profile/portlandpolicebureau/viz/New_Monthly_Neighborhood/MonthlyOffenseTotals). This document provides a summary of the evaluation as well as an applied demonstration of the synthetic control methodology.

## Overview of the Synthetic Control Method

The SC method is an increasing popular evaluation method that is well-suited for evaluating programs that take place at an aggregate level and affect a just small number of aggregate entities.[^1] The essence of the SC method is to create a "synthetic" version of the treated unit by weighting non-treated units such that the compound, synthetic control unit closely mimics the treated unit prior to the start of the intervention. Applied to the RJC evaluation, the SC method compares low-level crime rates in Cully to low-level crime rates in synthetic Cully, where synthetic Cully is constructed as a weighted combination of other Portland neighborhoods.

[^1]: For background on the synthetic control method, see: [Abadie, Alberto. "Using synthetic controls: Feasibility, Data Requirements, and Methodological Aspects." Journal of Economic Literature 59.2 (2021): 391-425.](https://www.aeaweb.org/articles?id=10.1257/jel.20191450)

In spirit, the synthetic control method is very similar to the comparative case study method, which compares outcomes in a given intervention unit (e.g., Cully) to outcomes in units not affected by the intervention (e.g., other Portland neighborhoods). However, whereas comparative case studies often use informal justifications for the choice of comparison units, the synthetic control method uses a data-driven, algorithmic procedure to identify and weight comparison units so that the synthetic unit is as similar as possible to the intervention unit in terms of key socio-demographic predictors and pre-intervention crime rates.

@fig-trends displays the intuition behind the method graphically. The solid line indicates the total number of low-level crimes reported in Cully for each quarter since 2015; the dashed line indicates the total number of low-level crimes in synthetic Cully. The two lines map closely to one another in both the pre and post intervention periods, suggesting the RJC pilot project did not have a significant impact on low-level crime in Cully.

<!--- As generated by the SC algorithm, synthetic Cully is a weighted combination of Glenfair, Overlook, Powellhurst-Gilbert, Parkrose, and three other neighborhoods in Portland (@fig-unit-weights). --->

## Implementation

The data are organized by neighborhood and quarter-year, from Q1 2015 through 2025 Q2. Our outcome of interest is *OffenseCount*, which captures the total number of low-level offenses (assault, motor vehicle theft, larceny, and vandalism) in a given neighborhood for a given quarter-year.

::: scrolling-output
```{r}
#| cache: true
#| warning: false

# insheet rawdata & clean
# source("01_Insheet&Clean.R")

# load & view data
df <- read_csv("data\\MultnomahAnalysisByQtr.csv")
df |> glimpse()
  
  

```
:::

<br>

We implement the SC method via the `tidysynth` package; click the code-fold below for line-by-line annotation.

```{r}
#| cache: true
#| warning: false
#| code-fold: true

df_out <- df |>
  synthetic_control(
    outcome = OffenseCount,
    unit = Neighborhood,
    time = time, # quarters from Q1 2015
    i_unit = "Cully",
    i_time = 37, # quarter corresponding to 2024 Q1
    generate_placebos = TRUE # generate placebo synthetic controls for inference
    ) |>
  # Generate aggregate predictors used to fit the weights
  # Vars from 2020 census
  generate_predictor(
    pop_2020 = pop_2020,
    median_age_2020 = median_age_2020,
    rentburd_pct_2020 = rentburd_pct_2020,
    pct_white_2020 = pct_white_2020,
    pct_hispanic_2020 = pct_hispanic_2020,
    pct_black_2020 = pct_black_2020,
    turnout_2020 = turnout_2020,
    no_ged_2020 = no_ged_2020,
    poverty_rate_2020 = poverty_rate_2020
  ) |>
  # lagged crime rates
  generate_predictor(
    time_window = 1:4,
    OffenseCount2015 = sum(OffenseCount, na.rm = TRUE)
  ) |>
  generate_predictor(
    time_window = 5:8,
    OffenseCount2016 = sum(OffenseCount, na.rm = TRUE)
  ) |>
  generate_predictor(
    time_window = 9:12,
    OffenseCount2017 = sum(OffenseCount, na.rm = TRUE)
  ) |>
  generate_predictor(
    time_window = 13:16,
    OffenseCount2018 = sum(OffenseCount, na.rm = TRUE)
  ) |>
  generate_predictor(
    time_window = 17:20,
    OffenseCount2019 = sum(OffenseCount, na.rm = TRUE)
  ) |>
  generate_predictor(
    time_window = 21:24,
    OffenseCount2020 = sum(OffenseCount, na.rm = TRUE)
  ) |>
  generate_predictor(
    time_window = 25:28,
    OffenseCount2021 = sum(OffenseCount, na.rm = TRUE)
  ) |>
  generate_predictor(
    time_window = 29:32,
    OffenseCount2022 = sum(OffenseCount, na.rm = TRUE)
  ) |>
  generate_predictor(
    time_window = 33:36,
    OffenseCount2023 = sum(OffenseCount, na.rm = TRUE)
  ) |>
  # Generate the fitted weights for the synthetic control
  generate_weights(optimization_window = 1:37, # time to use in the optimization task
                   margin_ipop = .02, 
                   sigf_ipop = 7,
                   bound_ipop = 6 # optimizer options
  ) |>
  # Generate the synthetic control
  generate_control()

```

### Main Results

@fig-trends plots low-level crime rates overtime in Cully and synthetic Cully. The figure shows that crime trends in syntheic Cully closely map those of actual Cully in the pre-intervention period,[^2] and that this pattern continues in the post-intervention period. Indeed, the ratio of the synthetic Cully's mean squared prediction error (MSPE) for the outcome variable between the pre vs. post intervention period is 1.05 (@tbl-inference), contrary to what we would expect if there were significant impacts that emerged in the post-intervention period.[^3] Overall, the results provide little evidence to suggest the RJC program has had an impact on low-level crime.

[^2]: Although pre-intevention trends between Cully and synthetic Cully map closely onto one another, the fit is not perfect. In a more extended implementation, we might consider using the [Augmented Syntheticl Control](https://sdfordham.github.io/pysyncon/augsynth.html) method to further minimize pre-intervention imbalance between synthetic Cully and Cully. Analogous to bias correction for inexact matching, the Augmented SC method uses an outcome model to estimate bias due to imperfect pretreatment fit and then de-biases the original SCM estimate. For background on the augmented synthetic control method, see: [Ben-Michael, Eli, Avi Feller, and Jesse Rothstein. "The augmented synthetic control method." Journal of the American Statistical Association 116.536 (2021): 1789-1803.](https://www.tandfonline.com/doi/full/10.1080/01621459.2021.1929245)

[^3]: Inference for the SC method is akin to a permutation test in which the effect estimate for the treated unit is compared to the distribution of effects for control units. As seen in @tbl-inference, Synthetic Cully MSPE ratio ranks 52 out of the 95 units in the sample, corresponding to a Fisher's exact p-value of .55. For full details, see the Inference section below.

<!-- We can see this more clearly by plotting the differences between Cully and Synthetic Cully overtime: --->

```{r}
#| include: false


plot_trends <- function(data,time_window=NULL){

  # Check if .meta is in data.
  if(!(".meta" %in% colnames(data))){stop("`.meta` column has been removed. `.meta` column needs to be included for `generte_control()` to work.")}

  # Grab meta data
  trt_time <- data$.meta[[1]]$treatment_time[1]
  time_index <- data$.meta[[1]]$time_index[1]
  outcome_name <- data$.meta[[1]]$outcome[1]

  # If no time window is specified for the plot, plot the entire series
  if(is.null(time_window)){ time_window <- unique(data$.original_data[[1]][[time_index]])}

  # Generate plot
  data %>%
    grab_synthetic_control(placebo = FALSE) %>%
    dplyr::filter(time_unit %in% time_window) %>%
    dplyr::rename(Synthetic= synth_y,
                  Observed= real_y) %>%
    tidyr::pivot_longer(cols = c(Observed,Synthetic)) %>%
    ggplot2::ggplot(ggplot2::aes(time_unit,value,color=name,linetype=name)) +
    ggplot2::geom_vline(xintercept = trt_time,color="black",linetype=2) +
    ggplot2::geom_line(size=1,alpha=.7) +
    ggplot2::geom_point() +
    ggplot2::scale_color_manual(values=c("grey50","#b41e7c")) +
    ggplot2::scale_linetype_manual(values=c(1,4)) +
    ggplot2::labs(color="",linetype="",y=outcome_name,x="Quarters since Q1 2015",
                  title=paste0("Time Series of the synthetic and observed ",outcome_name),
                  caption = "Dashed line denotes the time of the intervention.") +
    ggplot2::theme_minimal() +
    ggplot2::theme(legend.position = "bottom")
}




```

```{r}
#| warning: false
#| label: fig-trends
#| fig-cap: Low-level Crime in Cully and Synthetic Cully, 2015 Q1-2025 Q2
#| code-fold: true


df_out |> plot_trends()


```

```{r}
#| include: false

# for clarity of exposition, redefine plot_weights() so that near-zero weights are filtered out

plot_nonzero_weights <- function(data){

  # Combine the different type of weight outputs
  dplyr::bind_rows(

    grab_unit_weights(data,placebo = FALSE) %>%
      #filter out near zero weights
      dplyr::filter(weight > .005) %>%
      dplyr::mutate(type="Control Unit Weights (W)"),

    grab_predictor_weights(data,placebo = FALSE) %>%
      #filter out near zero weights
      dplyr::filter(weight > .005) %>%
      dplyr::mutate(type="Variable Weights (V)") %>%
      dplyr::rename(unit = variable)

  ) %>%

    # Generate plot
    dplyr::arrange(weight) %>%
    dplyr::mutate(unit = forcats::fct_reorder(unit,weight)) %>%
    ggplot2::ggplot(ggplot2::aes(unit,weight,fill=type,color=type)) +
    ggplot2::geom_col(show.legend = FALSE,alpha=.65) +
    ggplot2::coord_flip() +
    ggplot2::labs(x="") +
    ggplot2::facet_wrap(~type,ncol = 2,scales="free") +
    ggplot2::theme_minimal() +
    ggplot2::scale_fill_manual(values=c("#b41e7c","grey60")) +
    ggplot2::scale_color_manual(values=c("#b41e7c","grey60")) +
    ggplot2::theme(text = ggplot2::element_text(size = 14))
}



plot_nonzero_unit_weights <- function(data){


    grab_unit_weights(data,placebo = FALSE) %>%
      #filter out near zero weights
      dplyr::filter(weight > .005) %>%
      dplyr::mutate(type="Control Unit Weights (W)") %>%

    # Generate plot
    dplyr::arrange(weight) %>%
    dplyr::mutate(unit = forcats::fct_reorder(unit,weight)) %>%
    ggplot2::ggplot(ggplot2::aes(unit,weight,fill=type,color=type)) +
    ggplot2::geom_col(show.legend = FALSE,alpha=.65) +
    ggplot2::coord_flip() +
    ggplot2::labs(x="") +
    #ggplot2::facet_wrap(~type,ncol = 2,scales="free") +
    ggplot2::theme_minimal() +
    ggplot2::scale_fill_manual(values=c("#b41e7c","grey60")) +
    ggplot2::scale_color_manual(values=c("#b41e7c","grey60")) +
    ggplot2::theme(text = ggplot2::element_text(size = 14))
}




```

### Unit Weights

<!-- As generated by the SC algorithm, synthetic Cully is a weighted combination of Glenfair, Overlook, Powellhurst-Gilbert, four other neighborhoods of Portland (@fig-unit-weights). To identify these weights, the SC procedure used an optimization algorithm that identifies the weighted combination of neighborhoods that best resembles Cully prior to the start of RJC in 2024 in terms of pre-intervention crime rates **and other covariates specified in the model**. -->

The SC procedure uses an optimization algorithm to identify the weighted combination of neighborhoods that best resembles Cully prior to the start of the intervention in terms of its crime rates and other predictors of crime specified in the model.[^4] By default, the optimization algorithm minimizes synthetic Cully's mean squared prediction error across all pre-intervention periods, though [Abadie, Diamond, and Hainmueller (2015)](https://onlinelibrary.wiley.com/doi/full/10.1111/ajps.12116) propose a related method that uses cross-validation to minimize over-fitting.

[^4]: In addition to pre-intervention crime counts for each quarter from 2015 to 2023, I include population, percentage of residents below the poverty line, percentage without a GED, electoral turnout, and racial composition measures in the model.

Applied here, the SC algorithm constructs synthetic Cully as a weighted combination of Glenfair, Overlook, Powellhurst-Gilbert, four other neighborhoods of Portland (@fig-unit-weights).

```{r}
#| label: fig-unit-weights
#| fig-cap: Weights Used to Construct Synthetic Cully
#| code-fold: true


df_out |> plot_nonzero_unit_weights()

```

@tbl-balance shows that synthetic Cully is nearly identical to Cully in terms of its population, age distribution, percentage of residents below the poverty line, percentage without a GED, electoral turnout, racial composition, and pre-intervention crime counts from 2015 to 2023.

```{=html}
<!--
In applying the synthetic control method, we considered predictors such as population, age distribution, percentage of residents below the poverty line, percentage without a GED, electoral turnout, racial composition (including percentages of Black, White, and Hispanic residents), and pre-intervention crime counts from 2015 to 2023. Based on these variables, the synthetic control algorithm identified the weighted combination of comparison neighborhoods that most closely mirrors actual Cully. The results provide a near-identical match between Cully and Synthetic Cully, as documented in @tbl-balance. 

 While it is possible to incorporate additional covariates that might predict low-level crime, our current model already demonstrates a strong alignment between Synthetic Cully and actual Cully in terms of low-level crime rates prior to the intervention. Therefore, adding more covariates may not be necessary at this stage. -->
```

```{r}
#| label: tbl-balance
#| fig-cap: Cully vs. Synthetic Cully Balance Table
#| code-fold: true

df_out |> 
  grab_balance_table() |>
  mutate(across(where(is.numeric), ~ round(., 2))) |>
  flextable()

```

### Inference

Inference for the SC method follows the logic of permutation inference. The idea is to apply the SC method to every control unit in the sample and record the actual vs. synthetic gaps for each unit. We can then plot these gaps and visually assess whether the line associated synthetic Cully conspicuously differentiates itself from the rest, with small gaps prior to treatment and large gaps afterward.

As shown in @fig-inference, synthetic Cully does not stand out in this regard, lending credence to the conclusion that there is no statistically significant difference between Cully and Synthetic Cully.

```{r}
#| include: false


plot_placebos <- function(data,time_window=NULL,prune=TRUE){

  # Check if .meta is in data.
  if(!(".meta" %in% colnames(data))){stop("`.meta` column has been removed. `.meta` column needs to be included for `generte_control()` to work.")}

  # Grab meta data
  trt_time <- data$.meta[[1]]$treatment_time[1]
  time_index <- data$.meta[[1]]$time_index[1]
  treatment_unit <- data$.meta[[1]]$treatment_unit[1]
  unit_index <- data$.meta[[1]]$unit_index[1]
  outcome_name <- data$.meta[[1]]$outcome[1]

  # If no time window is specified for the plot, plot the entire series
  if(is.null(time_window)){ time_window <- unique(data$.original_data[[1]][[time_index]])}

  # Generate plot data
  plot_data <-
    data %>%
    grab_synthetic_control(placebo = TRUE) %>%
    dplyr::mutate(diff = real_y-synth_y) %>%
    dplyr::filter(time_unit %in% time_window) %>%
    dplyr::mutate(type_text = ifelse(.placebo==0,treatment_unit,"control units"),
                  type_text = factor(type_text,levels=c(treatment_unit,"control units")))


  # Pruning implementation-- if one of the donors falls outside two standard
  # deviations of the rest of the pool, it's dropped.
  caption <- ""
  if (prune){

    # Gather significance field
    sig_data = data %>% grab_significance(time_window = time_window)

    # Treated units Pre-Period RMSPE
    thres <-
      sig_data %>%
      dplyr::filter(type=="Treated") %>%
      dplyr::pull(pre_mspe) %>%
      sqrt(.)

    # Only retain units that are 2 times the treated unit RMSPE.
    retain_ <-
      sig_data %>%
      dplyr::select(unit_name,pre_mspe) %>%
      dplyr::filter(sqrt(pre_mspe) <= thres*2) %>%
      dplyr::pull(unit_name)

    plot_data <- plot_data %>% dplyr::filter(.id %in% retain_)
    caption <- "Pruned all placebo cases with a pre-period RMSPE exceeding two times the treated unit's pre-period RMSPE."
  }

  # Generate plot
  plot_data %>%
    ggplot2::ggplot(ggplot2::aes(time_unit,diff,group=.id,
                                 color=type_text,
                                 alpha=type_text,
                                 size=type_text)) +
    ggplot2::geom_hline(yintercept = 0,color="black",linetype=2) +
    ggplot2::geom_vline(xintercept = trt_time,color="black",linetype=3) +
    ggplot2::geom_line() +
    ggplot2::scale_color_manual(values=c("#b41e7c","grey60")) +
    ggplot2::scale_alpha_manual(values=c(1,.4)) +
    ggplot2::scale_size_manual(values=c(1,.5)) +
    ggplot2::labs(color="",alpha="",size="",y=outcome_name,x="Quarters since Q1 2015",
                  title=paste0("Synthetic vs Actual differences for each '",unit_index,"' in the donor pool"),
                  caption = caption) +
    ggplot2::theme_minimal() +
    ggplot2::theme(legend.position="bottom")
}






```

```{r}
#| label: fig-inference
#| fig-cap: Synthetic vs. Actual Differences for each Neighborhood in the Sample
#| code-fold: true

# note: by default, plot_placebos prunes all placebos 
# for which synthetic unit has poor pre-intervention fit

df_out %>% plot_placebos()

```

For exact inference, [Adabie et al. (2010)](https://j-hai.github.io/assets/pdf/scm.pdf) propose a way of constructing Fisher’s Exact p-values by dividing the post-intervention MSPE by the pre-intervention MSPE and then ranking all the cases by this ratio in descending order. A p-value is then constructed by taking the rank/total relative to the placebo pool. Intuitively, the idea is that if the synthetic control fits the observed time series well (low MSPE in the pre-period) and diverges in the post-period (high MSPE in the post-period) then there is a meaningful effect due to the intervention. Conversely, if the intervention had no effect, then the post-period and pre-period should continue to map onto one another fairly well, yielding a ratio close to 1. If the placebo units fit the data similarly, then we can’t reject the null hypothesis that there is no effect brought about by the intervention.

As shown in @tbl-inference, synthetic Cully ranks 52 out of 95 units in the sample, which corresponds to a p-value of .55.

```{r}
#| code-fold: true
#| label: tbl-inference
#| tbl-cap: Fisher's Exact P-Values

df_out |> 
  grab_significance() |>
  rename(Neighborhood = unit_name) |>
  mutate(across(where(is.numeric), ~ round(., 2))) |> # round numeric vars to 2 digits
  knitr::kable(format = "html", escape = FALSE) |>  # escape=FALSE allows HTML in cells
  kable_styling(bootstrap_options = c("striped", "hover")) |>
  scroll_box(width = "100%", height = "300px")  # Adds scroll if needed

```

````{=html}
<!---

::: {.scrolling-output}


```{r}
#| code-fold: true

df_out |> 
  grab_significance() |>
  mutate(across(where(is.numeric), ~ round(., 2))) |> # round numeric vars to 2 digits
  gt()

```


:::

-->
````
